{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install tensorflow\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install --upgrade numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape from file (187867, 30)\n",
      "After removing deltastrike within [-50, 50] (94202, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/npacey/Nathan-Testing/ML-for-American-Style-Stock-Options/Version 2.0/PrepareOptionsData.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['deltaDays'] = data['quoteDate'].diff()\n",
      "/home/npacey/Nathan-Testing/ML-for-American-Style-Stock-Options/Version 2.0/PrepareOptionsData.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['weekday'] = data['quoteDate'].dt.dayofweek\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used 814 contracts total\n",
      "Done, made data set with 48809 samples\n",
      "Dataframe shape from file (137380, 30)\n",
      "After removing deltastrike within [-50, 50] (94259, 30)\n",
      "Used 695 contracts total\n",
      "Done, made data set with 38239 samples\n"
     ]
    }
   ],
   "source": [
    "# gather datasets for each ticker defined\n",
    "from PrepareOptionsData import produceXYDataSets\n",
    "import warnings\n",
    "\n",
    "\n",
    "tickers = ['AAPL', 'AMD']\n",
    "option_type = 'C'\n",
    "#  represents the number of previous data points (or \"steps back\") to consider when training\n",
    "ns_back = 20\n",
    "\n",
    "# declare a dict to contain the x, y data for each ticker\n",
    "stock_data_dict = {}\n",
    "\n",
    "x_train_all = []\n",
    "y_train_all = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "       \n",
    "        x_train_ticker, y_train_ticker = produceXYDataSets(ticker, option_type, ns_back)\n",
    "        x_train_all.append(x_train_ticker)\n",
    "        y_train_all.append(y_train_ticker)\n",
    "    \n",
    "        # fill the dict with the ticker name as the key and then the associated x and y\n",
    "        stock_data_dict[ticker] = (x_train_ticker, y_train_ticker)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process ticker {ticker}: {e}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 23:16:55.373100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/software/quadis/latest/quadis/build/lib:/opt/conda/lib\n",
      "2024-02-22 23:16:55.373139: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[15.8 , 16.5 ],\n",
      "       [18.7 , 20.75],\n",
      "       [19.1 , 23.  ],\n",
      "       ...,\n",
      "       [ 1.91,  1.98],\n",
      "       [ 1.69,  1.78],\n",
      "       [ 1.79,  1.86]]), array([[42.2 , 45.5 ],\n",
      "       [44.2 , 47.05],\n",
      "       [43.2 , 46.55],\n",
      "       ...,\n",
      "       [ 0.4 ,  0.46],\n",
      "       [ 0.68,  0.72],\n",
      "       [ 1.09,  1.16]])]\n",
      "Shape of y_train_all: (87048, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 23:16:57.166294: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/software/quadis/latest/quadis/build/lib:/opt/conda/lib\n",
      "2024-02-22 23:16:57.166328: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-02-22 23:16:57.166355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2024-02-22 23:16:57.166577: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_lstm: (87048, 20, 6)\n"
     ]
    }
   ],
   "source": [
    "# prepare data for ML model\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, Dropout, LayerNormalization, Concatenate, StringLookup\n",
    "\n",
    "# the training set represents 80% of the data given to the model\n",
    "# the test represents the 20% of the data to validate the model\n",
    "# Assuming x_train and y_train are your data arrays\n",
    "\n",
    "print(y_train_all)\n",
    "# Concatenate the lists into numpy arrays\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# concat the data from each ticker into a continous stream array\n",
    "x_train = np.concatenate(x_train_all, axis=0)\n",
    "\n",
    "# Check if y_train_all is a list of arrays\n",
    "if isinstance(y_train_all, list) and all(isinstance(elem, np.ndarray) for elem in y_train_all):\n",
    "    # Concatenate all arrays in the list\n",
    "    y_train_all_np = np.concatenate(y_train_all, axis=0)\n",
    "else:\n",
    "    # If y_train_all is not a list of arrays, handle it accordingly\n",
    "    raise ValueError(\"y_train_all is not a list of NumPy arrays\")\n",
    "\n",
    "# Now y_train_all is a single NumPy array\n",
    "print(\"Shape of y_train_all:\", y_train_all_np.shape)\n",
    "\n",
    "# Continue with the rest of your code\n",
    "\n",
    "#y_train = np.concatenate(y_train_all, axis=0)\n",
    "# Extract contract names\n",
    "x_contract_names = x_train[:, 0]\n",
    "\n",
    "# Create and adapt the StringLookup layer\n",
    "string_lookup = StringLookup(output_mode=\"multi_hot\")\n",
    "string_lookup.adapt(x_contract_names)\n",
    "\n",
    "# Now, `string_lookup` can transform your contract names\n",
    "# Transform your contract names dataset\n",
    "transformed_contract_names = string_lookup(x_contract_names)\n",
    "\n",
    "\n",
    "# Adjust the slicing indices for x_data and x_stock_data\n",
    "# Assuming the next 5 elements after the contract name are still your features\n",
    "x_data = x_train[:, 1:6]  # Adjust indices as needed\n",
    "x_stock_data = x_train[:, 6:]  # Assuming stock prices start from the 7th element\n",
    "\n",
    "min_max_scaler_stockdata = preprocessing.MinMaxScaler()\n",
    "min_max_scaler_data = preprocessing.MinMaxScaler()\n",
    "\n",
    "\n",
    "x_stockdata_scaled = min_max_scaler_stockdata.fit_transform(x_stock_data)\n",
    "#print(x_stockdata_scaled)\n",
    "\n",
    "x_data_scaled = min_max_scaler_data.fit_transform(x_data)\n",
    "#print(x_data_scaled)\n",
    "\n",
    "# x_stockdata_scaled is temporal data with shape [samples, time steps]\n",
    "# Reshape x_stockdata_scaled to [samples, time steps, features] if it's not already in 3D\n",
    "if len(x_stockdata_scaled.shape) == 2:\n",
    "    # Assuming each row is a time step and you have only one feature per time step\n",
    "    x_stockdata_scaled = np.expand_dims(x_stockdata_scaled, axis=2)\n",
    "\n",
    "# Now x_stockdata_scaled should be 3D\n",
    "# Repeat x_data_scaled to match the time steps in x_stockdata_scaled\n",
    "# and x_data_scaled are additional features that we will append to each time step\n",
    "x_data_scaled_repeated = np.repeat(np.expand_dims(x_data_scaled, 1), x_stockdata_scaled.shape[1], axis=1)\n",
    "\n",
    "# Concatenate along the last dimension\n",
    "x_lstm = np.concatenate((x_stockdata_scaled, x_data_scaled_repeated), axis=2)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "x_lstm = np.array(x_lstm)\n",
    "\n",
    "# Check the shapes\n",
    "print(\"Shape of x_lstm:\", x_lstm.shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Calculate the number of samples for the test set (20% of total samples)\n",
    "test_size = int(0.2 * len(x_lstm))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train = x_lstm[:-test_size]\n",
    "x_test = x_lstm[-test_size:]\n",
    "y_train = y_train_all_np[:-test_size]\n",
    "y_test = y_train_all_np[-test_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values have been removed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'keras.layers.preprocessing.string_lookup.StringLookup'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10353/813165007.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m model = build_gru_model_2(\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mstring_lookup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcontract_input_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Adjust based on your contract name processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nathan-Testing/ML-for-American-Style-Stock-Options/Version 2.0/RNN_model_GRU_2.py\u001b[0m in \u001b[0;36mbuild_gru_model_2\u001b[0;34m(x_contract_names, contract_input_shape, option_data_shape, stock_data_shape)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mstring_lookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringLookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multi_hot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Adapt with actual contract names data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mstring_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_contract_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Define inputs for each type of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/preprocessing/string_lookup.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0marray\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \"\"\"\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# Overridden methods from IndexLookup.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1146\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1150\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    982\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'keras.layers.preprocessing.string_lookup.StringLookup'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "from RNN_model_GRU_2 import build_gru_model_2\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Check if y_train needs reshaping\n",
    "if len(y_train.shape) == 1:\n",
    "    # If y_train is expected to have only one target value per sample\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Check again for NaN values\n",
    "if np.any(np.isnan(x_train)) or np.any(np.isnan(y_train)):\n",
    "    print(\"NaN values are still present\")\n",
    "else:\n",
    "    print(\"NaN values have been removed\")\n",
    "\n",
    "model_name = 'split_options_GRU_2'\n",
    "# Adjust how you call the model to fit the new structure\n",
    "\n",
    "string_lookup = StringLookup(output_mode=\"multi_hot\")\n",
    "string_lookup.adapt(x_contract_names)\n",
    "\n",
    "\n",
    "model = build_gru_model_2(\n",
    "    string_lookup,\n",
    "    contract_input_shape=(1,),  # Adjust based on your contract name processing\n",
    "    option_data_shape=x_data.shape[1:],  # Shape of option-related features\n",
    "    stock_data_shape=x_stock_data.shape[1:]  # Shape of stock-related features\n",
    ")\n",
    "\n",
    "# When fitting the model, pass the preprocessed contract names and other inputs\n",
    "history = model.fit(\n",
    "    [transformed_contract_names, x_data, x_stock_data], y_train,\n",
    "    epochs=10, batch_size=64, validation_split=0.2\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluate on the testing data:\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Predictions on the test set\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Save the model\n",
    "model.save(model_name+'_model.h5')\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")\n",
    "print(f\"Mean Absolute Error on Test Set: {mae}\")\n",
    "\n",
    "\n",
    "# Function to calculate Mean Absolute Percentage Error\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    bid_true = y_true[:][0]\n",
    "    ask_true = y_true[:][1]\n",
    "    \n",
    "    bid_pred = y_pred[:][0]\n",
    "    ask_pred = y_pred[:][1]\n",
    "    \n",
    "    bid_error = np.mean(np.abs((bid_true-bid_pred)/bid_true))*100\n",
    "    ask_error = np.mean(np.abs((ask_true-ask_pred)/ask_true))*100\n",
    "    \n",
    "    \n",
    "    return [bid_error, ask_error]\n",
    "\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "print(\"\\nBid error,        Ask Error\")\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions against actual values\n",
    "# Assuming y_test and y_pred are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test[:, 0], label='Actual Bid', color='blue')\n",
    "plt.plot(predictions[:, 0], label='Predicted Bid', color='red', linestyle='--')\n",
    "#plt.plot(y_test[:, 1], label='Actual Ask', color='green')\n",
    "#plt.plot(predictions[:, 1], label='Predicted Ask', color='orange', linestyle='--')\n",
    "plt.title('Actual vs Predicted Bid Prices')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Assuming y_test and predictions are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "actual_bid_prices = y_test[:, 0]\n",
    "predicted_bid_prices = predictions[:, 0]\n",
    "\n",
    "# Calculate absolute percentage error for bids, avoiding divide by zero\n",
    "absolute_error_bid = np.abs(actual_bid_prices - predicted_bid_prices)\n",
    "absolute_error_bid_percent = np.where(actual_bid_prices != 0, (absolute_error_bid / actual_bid_prices) * 100, 0)\n",
    "\n",
    "# Define the range for the histogram bins (0% to 500% with 100 bins)\n",
    "bins = np.linspace(0, 500, 100)\n",
    "\n",
    "# Plot a histogram of the absolute percentage errors within the specified range\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(absolute_error_bid_percent, bins=bins, edgecolor='k', color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Percentage Error for Bid Prices')\n",
    "plt.xlabel('Absolute Percentage Error (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot a bar graph of the absolute errors for each sample\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(absolute_error_bid, color='blue', alpha=0.7)\n",
    "plt.title('Absolute Error for Bid Prices (Sample-wise)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions against actual values\n",
    "# Assuming y_test and y_pred are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test[:, 1], label='Actual Ask', color='green')\n",
    "plt.plot(predictions[:, 1], label='Predicted Ask', color='orange', linestyle='--')\n",
    "plt.title('Actual vs Predicted Ask Prices')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Assuming y_test and predictions are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "actual_ask_prices = y_test[:, 1]\n",
    "predicted_ask_prices = predictions[:, 1]\n",
    "\n",
    "# Calculate absolute percentage error for bids, avoiding divide by zero\n",
    "absolute_error_ask = np.abs(actual_ask_prices - predicted_ask_prices)\n",
    "absolute_error_ask_percent = np.where(actual_ask_prices != 0, (absolute_error_ask / actual_ask_prices) * 100, 0)\n",
    "\n",
    "# Define the range for the histogram bins (0% to 500% with 100 bins)\n",
    "bins = np.linspace(0, 500, 100)\n",
    "\n",
    "# Plot a histogram of the absolute percentage errors for asks\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(absolute_error_ask_percent, bins=bins, edgecolor='k', color='green', alpha=0.7)\n",
    "plt.title('Histogram of Absolute Percentage Error for Ask Prices')\n",
    "plt.xlabel('Absolute Percentage Error (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot a bar graph of the absolute errors for each sample\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(absolute_error_ask, color='green', alpha=0.7)\n",
    "plt.title('Absolute Error for Ask Prices (Sample-wise)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the predictions against actual values\n",
    "# Assuming y_test and y_pred are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "plt.figure(figsize=(12, 6))\n",
    "#plt.plot(y_test[-100:, 0], label='Actual Bid', color='blue')\n",
    "#plt.plot(predictions[-100:, 0], label='Predicted Bid', color='red', linestyle='--')\n",
    "plt.plot(y_test[-100:, 1], label='Actual Ask', color='green')\n",
    "plt.plot(predictions[-100:, 1], label='Predicted Ask', color='orange', linestyle='--')\n",
    "plt.title('Actual vs Predicted Ask Prices')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the predictions against actual values\n",
    "# Assuming y_test and y_pred are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test[-100:, 0], label='Actual Bid', color='blue')\n",
    "plt.plot(predictions[-100:, 0], label='Predicted Bid', color='red', linestyle='--')\n",
    "#plt.plot(y_test[:, 1], label='Actual Ask', color='green')\n",
    "#plt.plot(predictions[:, 1], label='Predicted Ask', color='orange', linestyle='--')\n",
    "plt.title('Actual vs Predicted Bid Prices')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the predictions against actual values\n",
    "# Assuming y_test and y_pred are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test[:10, 0], label='Actual Bid', color='blue')\n",
    "plt.plot(predictions[:10, 0], label='Predicted Bid', color='red', linestyle='--')\n",
    "#plt.plot(y_test[:, 1], label='Actual Ask', color='green')\n",
    "#plt.plot(predictions[:, 1], label='Predicted Ask', color='orange', linestyle='--')\n",
    "plt.title('Actual vs Predicted Bid Prices')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the predictions against actual values\n",
    "# Assuming y_test and y_pred are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "plt.figure(figsize=(12, 6))\n",
    "#plt.plot(y_test[:10, 0], label='Actual Bid', color='blue')\n",
    "#plt.plot(predictions[:10, 0], label='Predicted Bid', color='red', linestyle='--')\n",
    "plt.plot(y_test[:10, 1], label='Actual Ask', color='green')\n",
    "plt.plot(predictions[:10, 1], label='Predicted Ask', color='orange', linestyle='--')\n",
    "plt.title('Actual vs Predicted Bid Prices')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess the new ticker's data\n",
    "new_ticker = 'AMZN'  # Replace with the new ticker symbol\n",
    "x_test, y_test = produceXYDataSets(new_ticker, \"C\", 20)\n",
    "\n",
    "# Scale the test data using the same scalers as the training data\n",
    "# Assuming min_max_scaler_stockdata and min_max_scaler_data are already fitted with training data\n",
    "x_test_data = x_test[:,:5]\n",
    "x_test_stockdata = x_test[:,5:]\n",
    "x_test_stockdata_scaled = min_max_scaler_stockdata.transform(x_test_stockdata)\n",
    "x_test_data_scaled = min_max_scaler_data.transform(x_test_data)\n",
    "\n",
    "# Prepare the data for LSTM (reshape if necessary)\n",
    "x_test_lstm = np.concatenate((np.expand_dims(x_test_stockdata_scaled, axis=2), np.repeat(np.expand_dims(x_test_data_scaled, 1), x_test_stockdata_scaled.shape[1], axis=1)), axis=2)\n",
    "\n",
    "# Make predictions\n",
    "predictions_test = model.predict(x_test_lstm)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "predictions_test_original = predictions_test\n",
    "\n",
    "# Compare predictions with actual values\n",
    "# ... (You can use a similar plotting function as before to visualize the results)\n",
    "\n",
    "# Example: Plotting the results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test[:, 0], label='Real Bid', color='blue')\n",
    "plt.plot(predictions_test_original[:, 0], label='Predicted Bid', color='red', linestyle='--')\n",
    "plt.plot(y_test[:, 1], label='Real Ask', color='green')\n",
    "plt.plot(predictions_test_original[:, 1], label='Predicted Ask', color='orange', linestyle='--')\n",
    "plt.title(f'Real vs Predicted Bid/Ask Prices for {new_ticker}')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = mean_absolute_percentage_error(y_test, predictions_test_original)\n",
    "print(\"\\nBid error,        Ask Error\")\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions against actual values\n",
    "# Assuming y_test and y_pred are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test[:, 0], label='Actual Bid', color='blue')\n",
    "plt.plot(predictions_test_original[:, 0], label='Predicted Bid', color='red', linestyle='--')\n",
    "#plt.plot(y_test[:, 1], label='Actual Ask', color='green')\n",
    "#plt.plot(predictions[:, 1], label='Predicted Ask', color='orange', linestyle='--')\n",
    "plt.title('Actual vs Predicted Bid Prices')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Assuming y_test and predictions are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "actual_bid_prices = y_test[:, 0]\n",
    "predicted_bid_prices = predictions_test_original[:, 0]\n",
    "\n",
    "# Calculate absolute percentage error for bids, avoiding divide by zero\n",
    "absolute_error_bid = np.abs(actual_bid_prices - predicted_bid_prices)\n",
    "absolute_error_bid_percentage = np.where(actual_bid_prices != 0, (absolute_error_bid / actual_bid_prices) * 100, 0)\n",
    "\n",
    "# Define the range for the histogram bins (0% to 500% with 100 bins)\n",
    "bins = np.linspace(0, 500, 100)\n",
    "\n",
    "# Plot a histogram of the absolute percentage errors\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(absolute_error_bid_percentage, bins=bins, edgecolor='k', color='blue', alpha=0.7)\n",
    "plt.title('Distributiuon of Percentage Error for Bid Prices')\n",
    "plt.xlabel('Absolute Percentage Error (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot a bar graph of the absolute  errors for each sample\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(absolute_error_bid, color='blue', alpha=0.7)\n",
    "plt.title('Absolute Error for Bid Prices (Sample-wise)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range for the histogram bins (0% to 500% with 100 bins)\n",
    "bins = np.linspace(0, 200, 100)\n",
    "\n",
    "# Plot a histogram of the absolute percentage errors\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(absolute_error_bid_percentage, bins=bins, edgecolor='k', color='blue', alpha=0.7)\n",
    "plt.title('Distributiuon of Percentage Error for Bid Prices on AMZN data')\n",
    "plt.xlabel('Absolute Percentage Error (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions against actual values\n",
    "# Assuming y_test and y_pred are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test[:, 1], label='Actual Ask', color='green')\n",
    "plt.plot(predictions_test_original[:, 1], label='Predicted Ask', color='orange', linestyle='--')\n",
    "plt.title('Actual vs Predicted Ask Prices')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Assuming y_test and predictions are 2D arrays with shape [samples, 2] (for bid and ask prices)\n",
    "actual_ask_prices = y_test[:, 1]\n",
    "predicted_ask_prices = predictions_test_original[:, 1]\n",
    "\n",
    "\n",
    "# Calculate absolute percentage error for bids, avoiding divide by zero\n",
    "absolute_error_ask = np.abs(actual_ask_prices - predicted_ask_prices)\n",
    "absolute_error_ask_percentage = np.where(actual_ask_prices != 0, (absolute_error_ask / actual_ask_prices) * 100, 0)\n",
    "\n",
    "# Define the range for the histogram bins (0% to 500% with 100 bins)\n",
    "bins = np.linspace(0, 500, 100)\n",
    "\n",
    "# Plot a histogram of the absolute percentage errors for asks\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(absolute_error_ask_percentage, bins=bins, edgecolor='k', color='green', alpha=0.7)\n",
    "plt.title('Histogram of Absolute Percentage Error for Ask Prices')\n",
    "plt.xlabel('Absolute Percentage Error (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot a bar graph of the absolute percentage errors for each sample\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(absolute_error_ask, color='green', alpha=0.7)\n",
    "plt.title('Absolute  Error for Ask Prices (Sample-wise)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range for the histogram bins (0% to 500% with 100 bins)\n",
    "bins = np.linspace(0, 200, 100)\n",
    "\n",
    "# Plot a histogram of the absolute percentage errors for asks\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(absolute_error_ask_percentage, bins=bins, edgecolor='k', color='green', alpha=0.7)\n",
    "plt.title('Histogram of Absolute Percentage Error for Ask Prices on AMZN data')\n",
    "plt.xlabel('Absolute Percentage Error (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test[-100:, 0], label='Real Bid', color='blue')\n",
    "plt.plot(predictions_test_original[-100:, 0], label='Predicted Bid', color='red', linestyle='--')\n",
    "plt.plot(y_test[-100:, 1], label='Real Ask', color='green')\n",
    "plt.plot(predictions_test_original[-100:, 1], label='Predicted Ask', color='orange', linestyle='--')\n",
    "plt.title(f'Real vs Predicted Bid/Ask Prices for {new_ticker}')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test[-10:, 0], label='Real Bid', color='blue')\n",
    "plt.plot(predictions_test_original[-10:, 0], label='Predicted Bid', color='red', linestyle='--')\n",
    "plt.plot(y_test[-10:, 1], label='Real Ask', color='green')\n",
    "plt.plot(predictions_test_original[-10:, 1], label='Predicted Ask', color='orange', linestyle='--')\n",
    "plt.title(f'Real vs Predicted Bid/Ask Prices for {new_ticker}')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
